=== Detailed log started at 2025-03-20 14:55:13 ===
## Behaviour Generator: PurposefulSuspiciousBehaviourGenerator{type=Purposeful, epsilon=0.35, stepsBeforeOptimal=30}



## Initial state:
(and (clear d)
 (ontable d)
 (handempty)
 (clear b)
 (ontable b)
 (clear a)
 (ontable a)
 (clear c)
 (ontable c)
)
Checking if completed enough steps to act optimal
Still acting suspicious
Randomising actions
Chosen Action: 
Action pick-up
Instantiations:
?X0 - block : c 
Preconditions:
(and (handempty)
  (clear c)
  (ontable c))
Effects:
(and (holding c)
  (not (handempty)
  (not (clear c)
  (not (ontable c))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (clear d)
 (ontable d)
 (clear b)
 (ontable b)
 (clear a)
 (ontable a)
 (holding c)
)
Checking if state has already been observed
State has not been observed
Mirroing delta: 1.0
Starting recognising
Planning for problem 1 starting
Setting initial state to current state
Generating plan
Plan's cost: 5.0
Reseting initial state of problem
Planning for problem 2 starting
Setting initial state to current state
Generating plan
Plan's cost: 7.0
Reseting initial state of problem
Planning for problem 3 starting
Setting initial state to current state
Generating plan
Plan's cost: 5.0
Reseting initial state of problem
Generating scores for problems
Score for problem 1: 2.718281828459045
Score for problem 2: 0.36787944117144233
Score for problem 3: 0.36787944117144233
Calculating summed score
Total score: 3.4540407108019298
Final probability: 0.7869860421615985
Final probability: 0.10650697891920076
Final probability: 0.10650697891920076
Recognising Complete!
Highest probability: 0.7869860421615985
Second highest: 0.10650697891920076
Difference between probabilities is greater than epsilon. Skipping action.
Chosen Action: 
Action pick-up
Instantiations:
?X0 - block : a 
Preconditions:
(and (handempty)
  (clear a)
  (ontable a))
Effects:
(and (holding a)
  (not (handempty)
  (not (clear a)
  (not (ontable a))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (clear d)
 (ontable d)
 (clear b)
 (ontable b)
 (holding a)
 (clear c)
 (ontable c)
)
Checking if state has already been observed
State has not been observed
Mirroing delta: 1.0
Starting recognising
Planning for problem 1 starting
Setting initial state to current state
Generating plan
Plan's cost: 7.0
Reseting initial state of problem
Planning for problem 2 starting
Setting initial state to current state
Generating plan
Plan's cost: 7.0
Reseting initial state of problem
Planning for problem 3 starting
Setting initial state to current state
Generating plan
Plan's cost: 5.0
Reseting initial state of problem
Generating scores for problems
Score for problem 1: 0.36787944117144233
Score for problem 2: 0.36787944117144233
Score for problem 3: 0.36787944117144233
Calculating summed score
Total score: 1.103638323514327
Final probability: 0.3333333333333333
Final probability: 0.3333333333333333
Final probability: 0.3333333333333333
Recognising Complete!
Highest probability: 0.3333333333333333
Second highest: 0.3333333333333333
Difference between probabilities is less than epsilon. Choosing action.
## Action Made:
Action pick-up
Instantiations:
?X0 - block : a 
Preconditions:
(and (handempty)
  (clear a)
  (ontable a))
Effects:
(and (holding a)
  (not (handempty)
  (not (clear a)
  (not (ontable a))

## New State:
(and (clear d)
 (ontable d)
 (clear b)
 (ontable b)
 (holding a)
 (clear c)
 (ontable c)
)



Checking if completed enough steps to act optimal
Still acting suspicious
Randomising actions
Chosen Action: 
Action stack
Instantiations:
?X0 - block : a 
?X1 - block : c 
Preconditions:
(and (holding a)
  (clear c))
Effects:
(and (handempty)
  (clear a)
  (on a c)
  (not (holding a)
  (not (clear c))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (clear d)
 (ontable d)
 (handempty)
 (clear b)
 (ontable b)
 (clear a)
 (ontable c)
 (on a c)
)
Checking if state has already been observed
State has not been observed
Mirroing delta: 2.0
Starting recognising
Planning for problem 1 starting
Setting initial state to current state
Generating plan
Plan's cost: 8.0
Reseting initial state of problem
Planning for problem 2 starting
Setting initial state to current state
Generating plan
Plan's cost: 8.0
Reseting initial state of problem
Planning for problem 3 starting
Setting initial state to current state
Generating plan
Plan's cost: 6.0
Reseting initial state of problem
Generating scores for problems
Score for problem 1: 0.1353352832366127
Score for problem 2: 0.1353352832366127
Score for problem 3: 0.1353352832366127
Calculating summed score
Total score: 0.4060058497098381
Final probability: 0.3333333333333333
Final probability: 0.3333333333333333
Final probability: 0.3333333333333333
Recognising Complete!
Highest probability: 0.3333333333333333
Second highest: 0.3333333333333333
Difference between probabilities is less than epsilon. Choosing action.
## Action Made:
Action stack
Instantiations:
?X0 - block : a 
?X1 - block : c 
Preconditions:
(and (holding a)
  (clear c))
Effects:
(and (handempty)
  (clear a)
  (on a c)
  (not (holding a)
  (not (clear c))

## New State:
(and (clear d)
 (ontable d)
 (handempty)
 (clear b)
 (ontable b)
 (clear a)
 (ontable c)
 (on a c)
)



Checking if completed enough steps to act optimal
Still acting suspicious
Randomising actions
Chosen Action: 
Action unstack
Instantiations:
?X0 - block : a 
?X1 - block : c 
Preconditions:
(and (handempty)
  (clear a)
  (on a c))
Effects:
(and (holding a)
  (clear c)
  (not (handempty)
  (not (clear a)
  (not (on a c))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (clear d)
 (ontable d)
 (clear b)
 (ontable b)
 (holding a)
 (clear c)
 (ontable c)
)
Checking if state has already been observed
State has been observed. Choosing another action
Chosen Action: 
Action pick-up
Instantiations:
?X0 - block : b 
Preconditions:
(and (handempty)
  (clear b)
  (ontable b))
Effects:
(and (holding b)
  (not (handempty)
  (not (clear b)
  (not (ontable b))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (clear d)
 (ontable d)
 (holding b)
 (clear a)
 (ontable c)
 (on a c)
)
Checking if state has already been observed
State has not been observed
Mirroing delta: 3.0
Starting recognising
Planning for problem 1 starting
Setting initial state to current state
Generating plan
Plan's cost: 9.0
Reseting initial state of problem
Planning for problem 2 starting
Setting initial state to current state
Generating plan
Plan's cost: 9.0
Reseting initial state of problem
Planning for problem 3 starting
Setting initial state to current state
Generating plan
Plan's cost: 7.0
Reseting initial state of problem
Generating scores for problems
Score for problem 1: 0.049787068367863944
Score for problem 2: 0.049787068367863944
Score for problem 3: 0.049787068367863944
Calculating summed score
Total score: 0.14936120510359183
Final probability: 0.33333333333333337
Final probability: 0.33333333333333337
Final probability: 0.33333333333333337
Recognising Complete!
Highest probability: 0.33333333333333337
Second highest: 0.33333333333333337
Difference between probabilities is less than epsilon. Choosing action.
## Action Made:
Action pick-up
Instantiations:
?X0 - block : b 
Preconditions:
(and (handempty)
  (clear b)
  (ontable b))
Effects:
(and (holding b)
  (not (handempty)
  (not (clear b)
  (not (ontable b))

## New State:
(and (clear d)
 (ontable d)
 (holding b)
 (clear a)
 (ontable c)
 (on a c)
)



Checking if completed enough steps to act optimal
Still acting suspicious
Randomising actions
Chosen Action: 
Action put-down
Instantiations:
?X0 - block : b 
Preconditions:
(and (holding b))
Effects:
(and (handempty)
  (clear b)
  (ontable b)
  (not (holding b))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (clear d)
 (ontable d)
 (handempty)
 (clear b)
 (ontable b)
 (clear a)
 (ontable c)
 (on a c)
)
Checking if state has already been observed
State has been observed. Choosing another action
Chosen Action: 
Action stack
Instantiations:
?X0 - block : b 
?X1 - block : d 
Preconditions:
(and (clear d)
  (holding b))
Effects:
(and (handempty)
  (clear b)
  (on b d)
  (not (clear d)
  (not (holding b))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (ontable d)
 (handempty)
 (clear b)
 (clear a)
 (ontable c)
 (on b d)
 (on a c)
)
Checking if state has already been observed
State has not been observed
Mirroing delta: 4.0
Starting recognising
Planning for problem 1 starting
Setting initial state to current state
Generating plan
Plan's cost: 10.0
Reseting initial state of problem
Planning for problem 2 starting
Setting initial state to current state
Generating plan
Plan's cost: 8.0
Reseting initial state of problem
Planning for problem 3 starting
Setting initial state to current state
Generating plan
Plan's cost: 6.0
Reseting initial state of problem
Generating scores for problems
Score for problem 1: 0.01831563888873418
Score for problem 2: 0.1353352832366127
Score for problem 3: 0.1353352832366127
Calculating summed score
Total score: 0.28898620536195957
Final probability: 0.06337893833303761
Final probability: 0.46831053083348123
Final probability: 0.46831053083348123
Recognising Complete!
Highest probability: 0.46831053083348123
Second highest: 0.46831053083348123
Difference between probabilities is less than epsilon. Choosing action.
## Action Made:
Action stack
Instantiations:
?X0 - block : b 
?X1 - block : d 
Preconditions:
(and (clear d)
  (holding b))
Effects:
(and (handempty)
  (clear b)
  (on b d)
  (not (clear d)
  (not (holding b))

## New State:
(and (ontable d)
 (handempty)
 (clear b)
 (clear a)
 (ontable c)
 (on b d)
 (on a c)
)



Checking if completed enough steps to act optimal
Still acting suspicious
Randomising actions
Chosen Action: 
Action unstack
Instantiations:
?X0 - block : a 
?X1 - block : c 
Preconditions:
(and (handempty)
  (clear a)
  (on a c))
Effects:
(and (holding a)
  (clear c)
  (not (handempty)
  (not (clear a)
  (not (on a c))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (ontable d)
 (clear b)
 (holding a)
 (clear c)
 (ontable c)
 (on b d)
)
Checking if state has already been observed
State has not been observed
Mirroing delta: 5.0
Starting recognising
Planning for problem 1 starting
Setting initial state to current state
Generating plan
Plan's cost: 9.0
Reseting initial state of problem
Planning for problem 2 starting
Setting initial state to current state
Generating plan
Plan's cost: 7.0
Reseting initial state of problem
Planning for problem 3 starting
Setting initial state to current state
Generating plan
Plan's cost: 5.0
Reseting initial state of problem
Generating scores for problems
Score for problem 1: 0.049787068367863944
Score for problem 2: 0.36787944117144233
Score for problem 3: 0.36787944117144233
Calculating summed score
Total score: 0.7855459507107486
Final probability: 0.06337893833303762
Final probability: 0.4683105308334812
Final probability: 0.4683105308334812
Recognising Complete!
Highest probability: 0.4683105308334812
Second highest: 0.4683105308334812
Difference between probabilities is less than epsilon. Choosing action.
## Action Made:
Action unstack
Instantiations:
?X0 - block : a 
?X1 - block : c 
Preconditions:
(and (handempty)
  (clear a)
  (on a c))
Effects:
(and (holding a)
  (clear c)
  (not (handempty)
  (not (clear a)
  (not (on a c))

## New State:
(and (ontable d)
 (clear b)
 (holding a)
 (clear c)
 (ontable c)
 (on b d)
)



Checking if completed enough steps to act optimal
Still acting suspicious
Randomising actions
Chosen Action: 
Action stack
Instantiations:
?X0 - block : a 
?X1 - block : b 
Preconditions:
(and (clear b)
  (holding a))
Effects:
(and (handempty)
  (clear a)
  (on a b)
  (not (clear b)
  (not (holding a))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (ontable d)
 (handempty)
 (clear a)
 (clear c)
 (ontable c)
 (on b d)
 (on a b)
)
Checking if state has already been observed
State has not been observed
Mirroing delta: 6.0
Starting recognising
Planning for problem 1 starting
Setting initial state to current state
Generating plan
Plan's cost: 10.0
Reseting initial state of problem
Planning for problem 2 starting
Setting initial state to current state
Generating plan
Plan's cost: 8.0
Reseting initial state of problem
Planning for problem 3 starting
Setting initial state to current state
Generating plan
Plan's cost: 6.0
Reseting initial state of problem
Generating scores for problems
Score for problem 1: 0.01831563888873418
Score for problem 2: 0.1353352832366127
Score for problem 3: 0.1353352832366127
Calculating summed score
Total score: 0.28898620536195957
Final probability: 0.06337893833303761
Final probability: 0.46831053083348123
Final probability: 0.46831053083348123
Recognising Complete!
Highest probability: 0.46831053083348123
Second highest: 0.46831053083348123
Difference between probabilities is less than epsilon. Choosing action.
## Action Made:
Action stack
Instantiations:
?X0 - block : a 
?X1 - block : b 
Preconditions:
(and (clear b)
  (holding a))
Effects:
(and (handempty)
  (clear a)
  (on a b)
  (not (clear b)
  (not (holding a))

## New State:
(and (ontable d)
 (handempty)
 (clear a)
 (clear c)
 (ontable c)
 (on b d)
 (on a b)
)



Checking if completed enough steps to act optimal
Still acting suspicious
Randomising actions
Chosen Action: 
Action pick-up
Instantiations:
?X0 - block : c 
Preconditions:
(and (handempty)
  (clear c)
  (ontable c))
Effects:
(and (holding c)
  (not (handempty)
  (not (clear c)
  (not (ontable c))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (ontable d)
 (clear a)
 (holding c)
 (on b d)
 (on a b)
)
Checking if state has already been observed
State has not been observed
Mirroing delta: 7.0
Starting recognising
Planning for problem 1 starting
Setting initial state to current state
Generating plan
Plan's cost: 11.0
Reseting initial state of problem
Planning for problem 2 starting
Setting initial state to current state
Generating plan
Plan's cost: 9.0
Reseting initial state of problem
Planning for problem 3 starting
Setting initial state to current state
Generating plan
Plan's cost: 7.0
Reseting initial state of problem
Generating scores for problems
Score for problem 1: 0.006737946999085467
Score for problem 2: 0.049787068367863944
Score for problem 3: 0.049787068367863944
Calculating summed score
Total score: 0.10631208373481335
Final probability: 0.06337893833303762
Final probability: 0.46831053083348123
Final probability: 0.46831053083348123
Recognising Complete!
Highest probability: 0.46831053083348123
Second highest: 0.46831053083348123
Difference between probabilities is less than epsilon. Choosing action.
## Action Made:
Action pick-up
Instantiations:
?X0 - block : c 
Preconditions:
(and (handempty)
  (clear c)
  (ontable c))
Effects:
(and (holding c)
  (not (handempty)
  (not (clear c)
  (not (ontable c))

## New State:
(and (ontable d)
 (clear a)
 (holding c)
 (on b d)
 (on a b)
)



Checking if completed enough steps to act optimal
Still acting suspicious
Randomising actions
Chosen Action: 
Action stack
Instantiations:
?X0 - block : c 
?X1 - block : a 
Preconditions:
(and (clear a)
  (holding c))
Effects:
(and (handempty)
  (clear c)
  (on c a)
  (not (clear a)
  (not (holding c))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (ontable d)
 (handempty)
 (clear c)
 (on b d)
 (on a b)
 (on c a)
)
Checking if state has already been observed
State has not been observed
Mirroing delta: 8.0
Starting recognising
Planning for problem 1 starting
Setting initial state to current state
Generating plan
Plan's cost: 12.0
Reseting initial state of problem
Planning for problem 2 starting
Setting initial state to current state
Generating plan
Plan's cost: 10.0
Reseting initial state of problem
Planning for problem 3 starting
Setting initial state to current state
Generating plan
Plan's cost: 8.0
Reseting initial state of problem
Generating scores for problems
Score for problem 1: 0.0024787521766663585
Score for problem 2: 0.01831563888873418
Score for problem 3: 0.01831563888873418
Calculating summed score
Total score: 0.03911002995413472
Final probability: 0.06337893833303762
Final probability: 0.4683105308334811
Final probability: 0.4683105308334811
Recognising Complete!
Highest probability: 0.4683105308334811
Second highest: 0.4683105308334811
Difference between probabilities is less than epsilon. Choosing action.
## Action Made:
Action stack
Instantiations:
?X0 - block : c 
?X1 - block : a 
Preconditions:
(and (clear a)
  (holding c))
Effects:
(and (handempty)
  (clear c)
  (on c a)
  (not (clear a)
  (not (holding c))

## New State:
(and (ontable d)
 (handempty)
 (clear c)
 (on b d)
 (on a b)
 (on c a)
)



Checking if completed enough steps to act optimal
Still acting suspicious
Randomising actions
Chosen Action: 
Action unstack
Instantiations:
?X0 - block : c 
?X1 - block : a 
Preconditions:
(and (handempty)
  (clear c)
  (on c a))
Effects:
(and (clear a)
  (holding c)
  (not (handempty)
  (not (clear c)
  (not (on c a))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (ontable d)
 (clear a)
 (holding c)
 (on b d)
 (on a b)
)
Checking if state has already been observed
State has been observed. Choosing another action
Execution terminated: No more valid actions
Final state:
(and (ontable d)
 (handempty)
 (clear c)
 (on b d)
 (on a b)
 (on c a)
)
