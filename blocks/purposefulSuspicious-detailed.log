=== Detailed log started at 2025-04-15 17:53:47 ===
## Behaviour Generator: PurposefulSuspiciousBehaviourGenerator{type=Purposeful, epsilon=0.35, stepsBeforeOptimal=30}



## Initial state:
(and (clear e)
 (ontable e)
 (handempty)
 (clear f)
 (ontable f)
 (clear d)
 (ontable d)
 (clear b)
 (ontable b)
 (clear a)
 (ontable a)
 (clear c)
 (ontable c)
)
Checking if completed enough steps to act optimal
Still acting suspicious
Randomising actions
Chosen Action: 
Action pick-up
Instantiations:
?X0 - block : d 
Preconditions:
(and (handempty)
  (clear d)
  (ontable d))
Effects:
(and (holding d)
  (not (handempty)
  (not (clear d)
  (not (ontable d))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (clear e)
 (ontable e)
 (clear f)
 (ontable f)
 (holding d)
 (clear b)
 (ontable b)
 (clear a)
 (ontable a)
 (clear c)
 (ontable c)
)
Checking if state has already been observed
State has not been observed
Mirroing delta: 1.0
Starting recognising
Planning for problem 1 starting
Setting initial state to current state
Generating plan
Plan's cost: 11.0
Reseting initial state of problem
Planning for problem 2 starting
Setting initial state to current state
Generating plan
Plan's cost: 11.0
Reseting initial state of problem
Planning for problem 3 starting
Setting initial state to current state
Generating plan
Plan's cost: 3.0
Reseting initial state of problem
Generating scores for problems
Score for problem 1: 0.36787944117144233
Score for problem 2: 0.36787944117144233
Score for problem 3: 2.718281828459045
Calculating summed score
Total score: 3.4540407108019298
Final probability: 0.10650697891920076
Final probability: 0.10650697891920076
Final probability: 0.7869860421615985
Recognising Complete!
Highest probability: 0.7869860421615985
Second highest: 0.10650697891920076
Difference between probabilities is greater than epsilon. Skipping action.
Chosen Action: 
Action pick-up
Instantiations:
?X0 - block : f 
Preconditions:
(and (handempty)
  (clear f)
  (ontable f))
Effects:
(and (holding f)
  (not (handempty)
  (not (clear f)
  (not (ontable f))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (clear e)
 (ontable e)
 (holding f)
 (clear d)
 (ontable d)
 (clear b)
 (ontable b)
 (clear a)
 (ontable a)
 (clear c)
 (ontable c)
)
Checking if state has already been observed
State has not been observed
Mirroing delta: 1.0
Starting recognising
Planning for problem 1 starting
Setting initial state to current state
Generating plan
Plan's cost: 11.0
Reseting initial state of problem
Planning for problem 2 starting
Setting initial state to current state
Generating plan
Plan's cost: 11.0
Reseting initial state of problem
Planning for problem 3 starting
Setting initial state to current state
Generating plan
Plan's cost: 5.0
Reseting initial state of problem
Generating scores for problems
Score for problem 1: 0.36787944117144233
Score for problem 2: 0.36787944117144233
Score for problem 3: 0.36787944117144233
Calculating summed score
Total score: 1.103638323514327
Final probability: 0.3333333333333333
Final probability: 0.3333333333333333
Final probability: 0.3333333333333333
Recognising Complete!
Highest probability: 0.3333333333333333
Second highest: 0.3333333333333333
Difference between probabilities is less than epsilon. Choosing action.
## Action Made:
Action pick-up
Instantiations:
?X0 - block : f 
Preconditions:
(and (handempty)
  (clear f)
  (ontable f))
Effects:
(and (holding f)
  (not (handempty)
  (not (clear f)
  (not (ontable f))

## New State:
(and (clear e)
 (ontable e)
 (holding f)
 (clear d)
 (ontable d)
 (clear b)
 (ontable b)
 (clear a)
 (ontable a)
 (clear c)
 (ontable c)
)



Checking if completed enough steps to act optimal
Still acting suspicious
Randomising actions
Chosen Action: 
Action stack
Instantiations:
?X0 - block : f 
?X1 - block : c 
Preconditions:
(and (holding f)
  (clear c))
Effects:
(and (handempty)
  (clear f)
  (on f c)
  (not (holding f)
  (not (clear c))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (clear e)
 (ontable e)
 (handempty)
 (clear f)
 (clear d)
 (ontable d)
 (clear b)
 (ontable b)
 (clear a)
 (ontable a)
 (ontable c)
 (on f c)
)
Checking if state has already been observed
State has not been observed
Mirroing delta: 2.0
Starting recognising
Planning for problem 1 starting
Setting initial state to current state
Generating plan
Plan's cost: 12.0
Reseting initial state of problem
Planning for problem 2 starting
Setting initial state to current state
Generating plan
Plan's cost: 14.0
Reseting initial state of problem
Planning for problem 3 starting
Setting initial state to current state
Generating plan
Plan's cost: 6.0
Reseting initial state of problem
Generating scores for problems
Score for problem 1: 0.1353352832366127
Score for problem 2: 0.01831563888873418
Score for problem 3: 0.1353352832366127
Calculating summed score
Total score: 0.28898620536195957
Final probability: 0.46831053083348123
Final probability: 0.06337893833303761
Final probability: 0.46831053083348123
Recognising Complete!
Highest probability: 0.46831053083348123
Second highest: 0.46831053083348123
Difference between probabilities is less than epsilon. Choosing action.
## Action Made:
Action stack
Instantiations:
?X0 - block : f 
?X1 - block : c 
Preconditions:
(and (holding f)
  (clear c))
Effects:
(and (handempty)
  (clear f)
  (on f c)
  (not (holding f)
  (not (clear c))

## New State:
(and (clear e)
 (ontable e)
 (handempty)
 (clear f)
 (clear d)
 (ontable d)
 (clear b)
 (ontable b)
 (clear a)
 (ontable a)
 (ontable c)
 (on f c)
)



Checking if completed enough steps to act optimal
Still acting suspicious
Randomising actions
Chosen Action: 
Action pick-up
Instantiations:
?X0 - block : a 
Preconditions:
(and (handempty)
  (clear a)
  (ontable a))
Effects:
(and (holding a)
  (not (handempty)
  (not (clear a)
  (not (ontable a))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (clear e)
 (ontable e)
 (clear f)
 (clear d)
 (ontable d)
 (clear b)
 (ontable b)
 (holding a)
 (ontable c)
 (on f c)
)
Checking if state has already been observed
State has not been observed
Mirroing delta: 3.0
Starting recognising
Planning for problem 1 starting
Setting initial state to current state
Generating plan
Plan's cost: 13.0
Reseting initial state of problem
Planning for problem 2 starting
Setting initial state to current state
Generating plan
Plan's cost: 13.0
Reseting initial state of problem
Planning for problem 3 starting
Setting initial state to current state
Generating plan
Plan's cost: 7.0
Reseting initial state of problem
Generating scores for problems
Score for problem 1: 0.049787068367863944
Score for problem 2: 0.049787068367863944
Score for problem 3: 0.049787068367863944
Calculating summed score
Total score: 0.14936120510359183
Final probability: 0.33333333333333337
Final probability: 0.33333333333333337
Final probability: 0.33333333333333337
Recognising Complete!
Highest probability: 0.33333333333333337
Second highest: 0.33333333333333337
Difference between probabilities is less than epsilon. Choosing action.
## Action Made:
Action pick-up
Instantiations:
?X0 - block : a 
Preconditions:
(and (handempty)
  (clear a)
  (ontable a))
Effects:
(and (holding a)
  (not (handempty)
  (not (clear a)
  (not (ontable a))

## New State:
(and (clear e)
 (ontable e)
 (clear f)
 (clear d)
 (ontable d)
 (clear b)
 (ontable b)
 (holding a)
 (ontable c)
 (on f c)
)



Checking if completed enough steps to act optimal
Still acting suspicious
Randomising actions
Chosen Action: 
Action stack
Instantiations:
?X0 - block : a 
?X1 - block : d 
Preconditions:
(and (clear d)
  (holding a))
Effects:
(and (handempty)
  (clear a)
  (on a d)
  (not (clear d)
  (not (holding a))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (clear e)
 (ontable e)
 (handempty)
 (clear f)
 (ontable d)
 (clear b)
 (ontable b)
 (clear a)
 (ontable c)
 (on f c)
 (on a d)
)
Checking if state has already been observed
State has not been observed
Mirroing delta: 4.0
Starting recognising
Planning for problem 1 starting
Setting initial state to current state
Generating plan
Plan's cost: 14.0
Reseting initial state of problem
Planning for problem 2 starting
Setting initial state to current state
Generating plan
Plan's cost: 14.0
Reseting initial state of problem
Planning for problem 3 starting
Setting initial state to current state
Generating plan
Plan's cost: 8.0
Reseting initial state of problem
Generating scores for problems
Score for problem 1: 0.01831563888873418
Score for problem 2: 0.01831563888873418
Score for problem 3: 0.01831563888873418
Calculating summed score
Total score: 0.054946916666202536
Final probability: 0.3333333333333333
Final probability: 0.3333333333333333
Final probability: 0.3333333333333333
Recognising Complete!
Highest probability: 0.3333333333333333
Second highest: 0.3333333333333333
Difference between probabilities is less than epsilon. Choosing action.
## Action Made:
Action stack
Instantiations:
?X0 - block : a 
?X1 - block : d 
Preconditions:
(and (clear d)
  (holding a))
Effects:
(and (handempty)
  (clear a)
  (on a d)
  (not (clear d)
  (not (holding a))

## New State:
(and (clear e)
 (ontable e)
 (handempty)
 (clear f)
 (ontable d)
 (clear b)
 (ontable b)
 (clear a)
 (ontable c)
 (on f c)
 (on a d)
)



Checking if completed enough steps to act optimal
Still acting suspicious
Randomising actions
Chosen Action: 
Action unstack
Instantiations:
?X0 - block : f 
?X1 - block : c 
Preconditions:
(and (handempty)
  (clear f)
  (on f c))
Effects:
(and (holding f)
  (clear c)
  (not (handempty)
  (not (clear f)
  (not (on f c))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (clear e)
 (ontable e)
 (holding f)
 (ontable d)
 (clear b)
 (ontable b)
 (clear a)
 (clear c)
 (ontable c)
 (on a d)
)
Checking if state has already been observed
State has not been observed
Mirroing delta: 5.0
Starting recognising
Planning for problem 1 starting
Setting initial state to current state
Generating plan
Plan's cost: 13.0
Reseting initial state of problem
Planning for problem 2 starting
Setting initial state to current state
Generating plan
Plan's cost: 13.0
Reseting initial state of problem
Planning for problem 3 starting
Setting initial state to current state
Generating plan
Plan's cost: 7.0
Reseting initial state of problem
Generating scores for problems
Score for problem 1: 0.049787068367863944
Score for problem 2: 0.049787068367863944
Score for problem 3: 0.049787068367863944
Calculating summed score
Total score: 0.14936120510359183
Final probability: 0.33333333333333337
Final probability: 0.33333333333333337
Final probability: 0.33333333333333337
Recognising Complete!
Highest probability: 0.33333333333333337
Second highest: 0.33333333333333337
Difference between probabilities is less than epsilon. Choosing action.
## Action Made:
Action unstack
Instantiations:
?X0 - block : f 
?X1 - block : c 
Preconditions:
(and (handempty)
  (clear f)
  (on f c))
Effects:
(and (holding f)
  (clear c)
  (not (handempty)
  (not (clear f)
  (not (on f c))

## New State:
(and (clear e)
 (ontable e)
 (holding f)
 (ontable d)
 (clear b)
 (ontable b)
 (clear a)
 (clear c)
 (ontable c)
 (on a d)
)



Checking if completed enough steps to act optimal
Still acting suspicious
Randomising actions
Chosen Action: 
Action stack
Instantiations:
?X0 - block : f 
?X1 - block : a 
Preconditions:
(and (holding f)
  (clear a))
Effects:
(and (handempty)
  (clear f)
  (on f a)
  (not (holding f)
  (not (clear a))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (clear e)
 (ontable e)
 (handempty)
 (clear f)
 (ontable d)
 (clear b)
 (ontable b)
 (clear c)
 (ontable c)
 (on f a)
 (on a d)
)
Checking if state has already been observed
State has not been observed
Mirroing delta: 6.0
Starting recognising
Planning for problem 1 starting
Setting initial state to current state
Generating plan
Plan's cost: 14.0
Reseting initial state of problem
Planning for problem 2 starting
Setting initial state to current state
Generating plan
Plan's cost: 14.0
Reseting initial state of problem
Planning for problem 3 starting
Setting initial state to current state
Generating plan
Plan's cost: 8.0
Reseting initial state of problem
Generating scores for problems
Score for problem 1: 0.01831563888873418
Score for problem 2: 0.01831563888873418
Score for problem 3: 0.01831563888873418
Calculating summed score
Total score: 0.054946916666202536
Final probability: 0.3333333333333333
Final probability: 0.3333333333333333
Final probability: 0.3333333333333333
Recognising Complete!
Highest probability: 0.3333333333333333
Second highest: 0.3333333333333333
Difference between probabilities is less than epsilon. Choosing action.
## Action Made:
Action stack
Instantiations:
?X0 - block : f 
?X1 - block : a 
Preconditions:
(and (holding f)
  (clear a))
Effects:
(and (handempty)
  (clear f)
  (on f a)
  (not (holding f)
  (not (clear a))

## New State:
(and (clear e)
 (ontable e)
 (handempty)
 (clear f)
 (ontable d)
 (clear b)
 (ontable b)
 (clear c)
 (ontable c)
 (on f a)
 (on a d)
)



Checking if completed enough steps to act optimal
Still acting suspicious
Randomising actions
Chosen Action: 
Action pick-up
Instantiations:
?X0 - block : b 
Preconditions:
(and (handempty)
  (clear b)
  (ontable b))
Effects:
(and (holding b)
  (not (handempty)
  (not (clear b)
  (not (ontable b))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (clear e)
 (ontable e)
 (clear f)
 (ontable d)
 (holding b)
 (clear c)
 (ontable c)
 (on f a)
 (on a d)
)
Checking if state has already been observed
State has not been observed
Mirroing delta: 7.0
Starting recognising
Planning for problem 1 starting
Setting initial state to current state
Generating plan
Plan's cost: 15.0
Reseting initial state of problem
Planning for problem 2 starting
Setting initial state to current state
Generating plan
Plan's cost: 15.0
Reseting initial state of problem
Planning for problem 3 starting
Setting initial state to current state
Generating plan
Plan's cost: 9.0
Reseting initial state of problem
Generating scores for problems
Score for problem 1: 0.006737946999085467
Score for problem 2: 0.006737946999085467
Score for problem 3: 0.006737946999085467
Calculating summed score
Total score: 0.0202138409972564
Final probability: 0.33333333333333337
Final probability: 0.33333333333333337
Final probability: 0.33333333333333337
Recognising Complete!
Highest probability: 0.33333333333333337
Second highest: 0.33333333333333337
Difference between probabilities is less than epsilon. Choosing action.
## Action Made:
Action pick-up
Instantiations:
?X0 - block : b 
Preconditions:
(and (handempty)
  (clear b)
  (ontable b))
Effects:
(and (holding b)
  (not (handempty)
  (not (clear b)
  (not (ontable b))

## New State:
(and (clear e)
 (ontable e)
 (clear f)
 (ontable d)
 (holding b)
 (clear c)
 (ontable c)
 (on f a)
 (on a d)
)



Checking if completed enough steps to act optimal
Still acting suspicious
Randomising actions
Chosen Action: 
Action stack
Instantiations:
?X0 - block : b 
?X1 - block : e 
Preconditions:
(and (clear e)
  (holding b))
Effects:
(and (handempty)
  (clear b)
  (on b e)
  (not (clear e)
  (not (holding b))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (ontable e)
 (handempty)
 (clear f)
 (ontable d)
 (clear b)
 (clear c)
 (ontable c)
 (on f a)
 (on b e)
 (on a d)
)
Checking if state has already been observed
State has not been observed
Mirroing delta: 8.0
Starting recognising
Planning for problem 1 starting
Setting initial state to current state
Generating plan
Plan's cost: 16.0
Reseting initial state of problem
Planning for problem 2 starting
Setting initial state to current state
Generating plan
Plan's cost: 14.0
Reseting initial state of problem
Planning for problem 3 starting
Setting initial state to current state
Generating plan
Plan's cost: 8.0
Reseting initial state of problem
Generating scores for problems
Score for problem 1: 0.0024787521766663585
Score for problem 2: 0.01831563888873418
Score for problem 3: 0.01831563888873418
Calculating summed score
Total score: 0.03911002995413472
Final probability: 0.06337893833303762
Final probability: 0.4683105308334811
Final probability: 0.4683105308334811
Recognising Complete!
Highest probability: 0.4683105308334811
Second highest: 0.4683105308334811
Difference between probabilities is less than epsilon. Choosing action.
## Action Made:
Action stack
Instantiations:
?X0 - block : b 
?X1 - block : e 
Preconditions:
(and (clear e)
  (holding b))
Effects:
(and (handempty)
  (clear b)
  (on b e)
  (not (clear e)
  (not (holding b))

## New State:
(and (ontable e)
 (handempty)
 (clear f)
 (ontable d)
 (clear b)
 (clear c)
 (ontable c)
 (on f a)
 (on b e)
 (on a d)
)



Checking if completed enough steps to act optimal
Still acting suspicious
Randomising actions
Chosen Action: 
Action unstack
Instantiations:
?X0 - block : b 
?X1 - block : e 
Preconditions:
(and (handempty)
  (clear b)
  (on b e))
Effects:
(and (clear e)
  (holding b)
  (not (handempty)
  (not (clear b)
  (not (on b e))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (clear e)
 (ontable e)
 (clear f)
 (ontable d)
 (holding b)
 (clear c)
 (ontable c)
 (on f a)
 (on a d)
)
Checking if state has already been observed
State has been observed. Choosing another action
Chosen Action: 
Action unstack
Instantiations:
?X0 - block : f 
?X1 - block : a 
Preconditions:
(and (handempty)
  (clear f)
  (on f a))
Effects:
(and (holding f)
  (clear a)
  (not (handempty)
  (not (clear f)
  (not (on f a))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (ontable e)
 (holding f)
 (ontable d)
 (clear b)
 (clear a)
 (clear c)
 (ontable c)
 (on b e)
 (on a d)
)
Checking if state has already been observed
State has not been observed
Mirroing delta: 9.0
Starting recognising
Planning for problem 1 starting
Setting initial state to current state
Generating plan
Plan's cost: 15.0
Reseting initial state of problem
Planning for problem 2 starting
Setting initial state to current state
Generating plan
Plan's cost: 13.0
Reseting initial state of problem
Planning for problem 3 starting
Setting initial state to current state
Generating plan
Plan's cost: 7.0
Reseting initial state of problem
Generating scores for problems
Score for problem 1: 0.006737946999085467
Score for problem 2: 0.049787068367863944
Score for problem 3: 0.049787068367863944
Calculating summed score
Total score: 0.10631208373481335
Final probability: 0.06337893833303762
Final probability: 0.46831053083348123
Final probability: 0.46831053083348123
Recognising Complete!
Highest probability: 0.46831053083348123
Second highest: 0.46831053083348123
Difference between probabilities is less than epsilon. Choosing action.
## Action Made:
Action unstack
Instantiations:
?X0 - block : f 
?X1 - block : a 
Preconditions:
(and (handempty)
  (clear f)
  (on f a))
Effects:
(and (holding f)
  (clear a)
  (not (handempty)
  (not (clear f)
  (not (on f a))

## New State:
(and (ontable e)
 (holding f)
 (ontable d)
 (clear b)
 (clear a)
 (clear c)
 (ontable c)
 (on b e)
 (on a d)
)



Checking if completed enough steps to act optimal
Still acting suspicious
Randomising actions
Chosen Action: 
Action stack
Instantiations:
?X0 - block : f 
?X1 - block : c 
Preconditions:
(and (holding f)
  (clear c))
Effects:
(and (handempty)
  (clear f)
  (on f c)
  (not (holding f)
  (not (clear c))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (ontable e)
 (handempty)
 (clear f)
 (ontable d)
 (clear b)
 (clear a)
 (ontable c)
 (on f c)
 (on b e)
 (on a d)
)
Checking if state has already been observed
State has not been observed
Mirroing delta: 10.0
Starting recognising
Planning for problem 1 starting
Setting initial state to current state
Generating plan
Plan's cost: 16.0
Reseting initial state of problem
Planning for problem 2 starting
Setting initial state to current state
Generating plan
Plan's cost: 14.0
Reseting initial state of problem
Planning for problem 3 starting
Setting initial state to current state
Generating plan
Plan's cost: 8.0
Reseting initial state of problem
Generating scores for problems
Score for problem 1: 0.0024787521766663585
Score for problem 2: 0.01831563888873418
Score for problem 3: 0.01831563888873418
Calculating summed score
Total score: 0.03911002995413472
Final probability: 0.06337893833303762
Final probability: 0.4683105308334811
Final probability: 0.4683105308334811
Recognising Complete!
Highest probability: 0.4683105308334811
Second highest: 0.4683105308334811
Difference between probabilities is less than epsilon. Choosing action.
## Action Made:
Action stack
Instantiations:
?X0 - block : f 
?X1 - block : c 
Preconditions:
(and (holding f)
  (clear c))
Effects:
(and (handempty)
  (clear f)
  (on f c)
  (not (holding f)
  (not (clear c))

## New State:
(and (ontable e)
 (handempty)
 (clear f)
 (ontable d)
 (clear b)
 (clear a)
 (ontable c)
 (on f c)
 (on b e)
 (on a d)
)



Checking if completed enough steps to act optimal
Still acting suspicious
Randomising actions
Chosen Action: 
Action unstack
Instantiations:
?X0 - block : f 
?X1 - block : c 
Preconditions:
(and (handempty)
  (clear f)
  (on f c))
Effects:
(and (holding f)
  (clear c)
  (not (handempty)
  (not (clear f)
  (not (on f c))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (ontable e)
 (holding f)
 (ontable d)
 (clear b)
 (clear a)
 (clear c)
 (ontable c)
 (on b e)
 (on a d)
)
Checking if state has already been observed
State has been observed. Choosing another action
Chosen Action: 
Action unstack
Instantiations:
?X0 - block : b 
?X1 - block : e 
Preconditions:
(and (handempty)
  (clear b)
  (on b e))
Effects:
(and (clear e)
  (holding b)
  (not (handempty)
  (not (clear b)
  (not (on b e))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (clear e)
 (ontable e)
 (clear f)
 (ontable d)
 (holding b)
 (clear a)
 (ontable c)
 (on f c)
 (on a d)
)
Checking if state has already been observed
State has not been observed
Mirroing delta: 11.0
Starting recognising
Planning for problem 1 starting
Setting initial state to current state
Generating plan
Plan's cost: 15.0
Reseting initial state of problem
Planning for problem 2 starting
Setting initial state to current state
Generating plan
Plan's cost: 15.0
Reseting initial state of problem
Planning for problem 3 starting
Setting initial state to current state
Generating plan
Plan's cost: 9.0
Reseting initial state of problem
Generating scores for problems
Score for problem 1: 0.006737946999085467
Score for problem 2: 0.006737946999085467
Score for problem 3: 0.006737946999085467
Calculating summed score
Total score: 0.0202138409972564
Final probability: 0.33333333333333337
Final probability: 0.33333333333333337
Final probability: 0.33333333333333337
Recognising Complete!
Highest probability: 0.33333333333333337
Second highest: 0.33333333333333337
Difference between probabilities is less than epsilon. Choosing action.
## Action Made:
Action unstack
Instantiations:
?X0 - block : b 
?X1 - block : e 
Preconditions:
(and (handempty)
  (clear b)
  (on b e))
Effects:
(and (clear e)
  (holding b)
  (not (handempty)
  (not (clear b)
  (not (on b e))

## New State:
(and (clear e)
 (ontable e)
 (clear f)
 (ontable d)
 (holding b)
 (clear a)
 (ontable c)
 (on f c)
 (on a d)
)



Checking if completed enough steps to act optimal
Still acting suspicious
Randomising actions
Chosen Action: 
Action stack
Instantiations:
?X0 - block : b 
?X1 - block : f 
Preconditions:
(and (clear f)
  (holding b))
Effects:
(and (handempty)
  (clear b)
  (on b f)
  (not (clear f)
  (not (holding b))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (clear e)
 (ontable e)
 (handempty)
 (ontable d)
 (clear b)
 (clear a)
 (ontable c)
 (on f c)
 (on b f)
 (on a d)
)
Checking if state has already been observed
State has not been observed
Mirroing delta: 12.0
Starting recognising
Planning for problem 1 starting
Setting initial state to current state
Generating plan
Plan's cost: 16.0
Reseting initial state of problem
Planning for problem 2 starting
Setting initial state to current state
Generating plan
Plan's cost: 14.0
Reseting initial state of problem
Planning for problem 3 starting
Setting initial state to current state
Generating plan
Plan's cost: 8.0
Reseting initial state of problem
Generating scores for problems
Score for problem 1: 0.0024787521766663585
Score for problem 2: 0.01831563888873418
Score for problem 3: 0.01831563888873418
Calculating summed score
Total score: 0.03911002995413472
Final probability: 0.06337893833303762
Final probability: 0.4683105308334811
Final probability: 0.4683105308334811
Recognising Complete!
Highest probability: 0.4683105308334811
Second highest: 0.4683105308334811
Difference between probabilities is less than epsilon. Choosing action.
## Action Made:
Action stack
Instantiations:
?X0 - block : b 
?X1 - block : f 
Preconditions:
(and (clear f)
  (holding b))
Effects:
(and (handempty)
  (clear b)
  (on b f)
  (not (clear f)
  (not (holding b))

## New State:
(and (clear e)
 (ontable e)
 (handempty)
 (ontable d)
 (clear b)
 (clear a)
 (ontable c)
 (on f c)
 (on b f)
 (on a d)
)



Checking if completed enough steps to act optimal
Still acting suspicious
Randomising actions
Chosen Action: 
Action unstack
Instantiations:
?X0 - block : b 
?X1 - block : f 
Preconditions:
(and (handempty)
  (clear b)
  (on b f))
Effects:
(and (clear f)
  (holding b)
  (not (handempty)
  (not (clear b)
  (not (on b f))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (clear e)
 (ontable e)
 (clear f)
 (ontable d)
 (holding b)
 (clear a)
 (ontable c)
 (on f c)
 (on a d)
)
Checking if state has already been observed
State has been observed. Choosing another action
Chosen Action: 
Action unstack
Instantiations:
?X0 - block : a 
?X1 - block : d 
Preconditions:
(and (handempty)
  (clear a)
  (on a d))
Effects:
(and (clear d)
  (holding a)
  (not (handempty)
  (not (clear a)
  (not (on a d))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (clear e)
 (ontable e)
 (clear d)
 (ontable d)
 (clear b)
 (holding a)
 (ontable c)
 (on f c)
 (on b f)
)
Checking if state has already been observed
State has not been observed
Mirroing delta: 13.0
Starting recognising
Planning for problem 1 starting
Setting initial state to current state
Generating plan
Plan's cost: 15.0
Reseting initial state of problem
Planning for problem 2 starting
Setting initial state to current state
Generating plan
Plan's cost: 15.0
Reseting initial state of problem
Planning for problem 3 starting
Setting initial state to current state
Generating plan
Plan's cost: 7.0
Reseting initial state of problem
Generating scores for problems
Score for problem 1: 0.006737946999085467
Score for problem 2: 0.006737946999085467
Score for problem 3: 0.049787068367863944
Calculating summed score
Total score: 0.06326296236603487
Final probability: 0.10650697891920076
Final probability: 0.10650697891920076
Final probability: 0.7869860421615985
Recognising Complete!
Highest probability: 0.7869860421615985
Second highest: 0.10650697891920076
Difference between probabilities is greater than epsilon. Skipping action.
Chosen Action: 
Action pick-up
Instantiations:
?X0 - block : e 
Preconditions:
(and (clear e)
  (ontable e)
  (handempty))
Effects:
(and (holding e)
  (not (clear e)
  (not (ontable e)
  (not (handempty))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (holding e)
 (ontable d)
 (clear b)
 (clear a)
 (ontable c)
 (on f c)
 (on b f)
 (on a d)
)
Checking if state has already been observed
State has not been observed
Mirroing delta: 13.0
Starting recognising
Planning for problem 1 starting
Setting initial state to current state
Generating plan
Plan's cost: 17.0
Reseting initial state of problem
Planning for problem 2 starting
Setting initial state to current state
Generating plan
Plan's cost: 15.0
Reseting initial state of problem
Planning for problem 3 starting
Setting initial state to current state
Generating plan
Plan's cost: 9.0
Reseting initial state of problem
Generating scores for problems
Score for problem 1: 9.118819655545162E-4
Score for problem 2: 0.006737946999085467
Score for problem 3: 0.006737946999085467
Calculating summed score
Total score: 0.01438777596372545
Final probability: 0.06337893833303762
Final probability: 0.4683105308334812
Final probability: 0.4683105308334812
Recognising Complete!
Highest probability: 0.4683105308334812
Second highest: 0.4683105308334812
Difference between probabilities is less than epsilon. Choosing action.
## Action Made:
Action pick-up
Instantiations:
?X0 - block : e 
Preconditions:
(and (clear e)
  (ontable e)
  (handempty))
Effects:
(and (holding e)
  (not (clear e)
  (not (ontable e)
  (not (handempty))

## New State:
(and (holding e)
 (ontable d)
 (clear b)
 (clear a)
 (ontable c)
 (on f c)
 (on b f)
 (on a d)
)



Checking if completed enough steps to act optimal
Still acting suspicious
Randomising actions
Chosen Action: 
Action stack
Instantiations:
?X0 - block : e 
?X1 - block : b 
Preconditions:
(and (holding e)
  (clear b))
Effects:
(and (clear e)
  (handempty)
  (on e b)
  (not (holding e)
  (not (clear b))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (clear e)
 (handempty)
 (ontable d)
 (clear a)
 (ontable c)
 (on e b)
 (on f c)
 (on b f)
 (on a d)
)
Checking if state has already been observed
State has not been observed
Mirroing delta: 14.0
Starting recognising
Planning for problem 1 starting
Setting initial state to current state
Generating plan
Plan's cost: 18.0
Reseting initial state of problem
Planning for problem 2 starting
Setting initial state to current state
Generating plan
Plan's cost: 16.0
Reseting initial state of problem
Planning for problem 3 starting
Setting initial state to current state
Generating plan
Plan's cost: 10.0
Reseting initial state of problem
Generating scores for problems
Score for problem 1: 3.3546262790251185E-4
Score for problem 2: 0.0024787521766663585
Score for problem 3: 0.0024787521766663585
Calculating summed score
Total score: 0.005292966981235229
Final probability: 0.06337893833303762
Final probability: 0.4683105308334812
Final probability: 0.4683105308334812
Recognising Complete!
Highest probability: 0.4683105308334812
Second highest: 0.4683105308334812
Difference between probabilities is less than epsilon. Choosing action.
## Action Made:
Action stack
Instantiations:
?X0 - block : e 
?X1 - block : b 
Preconditions:
(and (holding e)
  (clear b))
Effects:
(and (clear e)
  (handempty)
  (on e b)
  (not (holding e)
  (not (clear b))

## New State:
(and (clear e)
 (handempty)
 (ontable d)
 (clear a)
 (ontable c)
 (on e b)
 (on f c)
 (on b f)
 (on a d)
)



Checking if completed enough steps to act optimal
Still acting suspicious
Randomising actions
Chosen Action: 
Action unstack
Instantiations:
?X0 - block : a 
?X1 - block : d 
Preconditions:
(and (handempty)
  (clear a)
  (on a d))
Effects:
(and (clear d)
  (holding a)
  (not (handempty)
  (not (clear a)
  (not (on a d))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (clear e)
 (clear d)
 (ontable d)
 (holding a)
 (ontable c)
 (on e b)
 (on f c)
 (on b f)
)
Checking if state has already been observed
State has not been observed
Mirroing delta: 15.0
Starting recognising
Planning for problem 1 starting
Setting initial state to current state
Generating plan
Plan's cost: 17.0
Reseting initial state of problem
Planning for problem 2 starting
Setting initial state to current state
Generating plan
Plan's cost: 15.0
Reseting initial state of problem
Planning for problem 3 starting
Setting initial state to current state
Generating plan
Plan's cost: 9.0
Reseting initial state of problem
Generating scores for problems
Score for problem 1: 9.118819655545162E-4
Score for problem 2: 0.006737946999085467
Score for problem 3: 0.006737946999085467
Calculating summed score
Total score: 0.01438777596372545
Final probability: 0.06337893833303762
Final probability: 0.4683105308334812
Final probability: 0.4683105308334812
Recognising Complete!
Highest probability: 0.4683105308334812
Second highest: 0.4683105308334812
Difference between probabilities is less than epsilon. Choosing action.
## Action Made:
Action unstack
Instantiations:
?X0 - block : a 
?X1 - block : d 
Preconditions:
(and (handempty)
  (clear a)
  (on a d))
Effects:
(and (clear d)
  (holding a)
  (not (handempty)
  (not (clear a)
  (not (on a d))

## New State:
(and (clear e)
 (clear d)
 (ontable d)
 (holding a)
 (ontable c)
 (on e b)
 (on f c)
 (on b f)
)



Checking if completed enough steps to act optimal
Still acting suspicious
Randomising actions
Chosen Action: 
Action put-down
Instantiations:
?X0 - block : a 
Preconditions:
(and (holding a))
Effects:
(and (handempty)
  (clear a)
  (ontable a)
  (not (holding a))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (clear e)
 (handempty)
 (clear d)
 (ontable d)
 (clear a)
 (ontable a)
 (ontable c)
 (on e b)
 (on f c)
 (on b f)
)
Checking if state has already been observed
State has not been observed
Mirroing delta: 16.0
Starting recognising
Planning for problem 1 starting
Setting initial state to current state
Generating plan
Plan's cost: 16.0
Reseting initial state of problem
Planning for problem 2 starting
Setting initial state to current state
Generating plan
Plan's cost: 14.0
Reseting initial state of problem
Planning for problem 3 starting
Setting initial state to current state
Generating plan
Plan's cost: 8.0
Reseting initial state of problem
Generating scores for problems
Score for problem 1: 0.0024787521766663585
Score for problem 2: 0.01831563888873418
Score for problem 3: 0.01831563888873418
Calculating summed score
Total score: 0.03911002995413472
Final probability: 0.06337893833303762
Final probability: 0.4683105308334811
Final probability: 0.4683105308334811
Recognising Complete!
Highest probability: 0.4683105308334811
Second highest: 0.4683105308334811
Difference between probabilities is less than epsilon. Choosing action.
## Action Made:
Action put-down
Instantiations:
?X0 - block : a 
Preconditions:
(and (holding a))
Effects:
(and (handempty)
  (clear a)
  (ontable a)
  (not (holding a))

## New State:
(and (clear e)
 (handempty)
 (clear d)
 (ontable d)
 (clear a)
 (ontable a)
 (ontable c)
 (on e b)
 (on f c)
 (on b f)
)



Checking if completed enough steps to act optimal
Still acting suspicious
Randomising actions
Chosen Action: 
Action pick-up
Instantiations:
?X0 - block : d 
Preconditions:
(and (handempty)
  (clear d)
  (ontable d))
Effects:
(and (holding d)
  (not (handempty)
  (not (clear d)
  (not (ontable d))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (clear e)
 (holding d)
 (clear a)
 (ontable a)
 (ontable c)
 (on e b)
 (on f c)
 (on b f)
)
Checking if state has already been observed
State has not been observed
Mirroing delta: 17.0
Starting recognising
Planning for problem 1 starting
Setting initial state to current state
Generating plan
Plan's cost: 17.0
Reseting initial state of problem
Planning for problem 2 starting
Setting initial state to current state
Generating plan
Plan's cost: 15.0
Reseting initial state of problem
Planning for problem 3 starting
Setting initial state to current state
Generating plan
Plan's cost: 9.0
Reseting initial state of problem
Generating scores for problems
Score for problem 1: 9.118819655545162E-4
Score for problem 2: 0.006737946999085467
Score for problem 3: 0.006737946999085467
Calculating summed score
Total score: 0.01438777596372545
Final probability: 0.06337893833303762
Final probability: 0.4683105308334812
Final probability: 0.4683105308334812
Recognising Complete!
Highest probability: 0.4683105308334812
Second highest: 0.4683105308334812
Difference between probabilities is less than epsilon. Choosing action.
## Action Made:
Action pick-up
Instantiations:
?X0 - block : d 
Preconditions:
(and (handempty)
  (clear d)
  (ontable d))
Effects:
(and (holding d)
  (not (handempty)
  (not (clear d)
  (not (ontable d))

## New State:
(and (clear e)
 (holding d)
 (clear a)
 (ontable a)
 (ontable c)
 (on e b)
 (on f c)
 (on b f)
)



Checking if completed enough steps to act optimal
Still acting suspicious
Randomising actions
Chosen Action: 
Action stack
Instantiations:
?X0 - block : d 
?X1 - block : e 
Preconditions:
(and (clear e)
  (holding d))
Effects:
(and (handempty)
  (clear d)
  (on d e)
  (not (clear e)
  (not (holding d))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (handempty)
 (clear d)
 (clear a)
 (ontable a)
 (ontable c)
 (on e b)
 (on f c)
 (on d e)
 (on b f)
)
Checking if state has already been observed
State has not been observed
Mirroing delta: 18.0
Starting recognising
Planning for problem 1 starting
Setting initial state to current state
Generating plan
Plan's cost: 18.0
Reseting initial state of problem
Planning for problem 2 starting
Setting initial state to current state
Generating plan
Plan's cost: 16.0
Reseting initial state of problem
Planning for problem 3 starting
Setting initial state to current state
Generating plan
Plan's cost: 10.0
Reseting initial state of problem
Generating scores for problems
Score for problem 1: 3.3546262790251185E-4
Score for problem 2: 0.0024787521766663585
Score for problem 3: 0.0024787521766663585
Calculating summed score
Total score: 0.005292966981235229
Final probability: 0.06337893833303762
Final probability: 0.4683105308334812
Final probability: 0.4683105308334812
Recognising Complete!
Highest probability: 0.4683105308334812
Second highest: 0.4683105308334812
Difference between probabilities is less than epsilon. Choosing action.
## Action Made:
Action stack
Instantiations:
?X0 - block : d 
?X1 - block : e 
Preconditions:
(and (clear e)
  (holding d))
Effects:
(and (handempty)
  (clear d)
  (on d e)
  (not (clear e)
  (not (holding d))

## New State:
(and (handempty)
 (clear d)
 (clear a)
 (ontable a)
 (ontable c)
 (on e b)
 (on f c)
 (on d e)
 (on b f)
)



Checking if completed enough steps to act optimal
Still acting suspicious
Randomising actions
Chosen Action: 
Action unstack
Instantiations:
?X0 - block : d 
?X1 - block : e 
Preconditions:
(and (handempty)
  (clear d)
  (on d e))
Effects:
(and (clear e)
  (holding d)
  (not (handempty)
  (not (clear d)
  (not (on d e))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (clear e)
 (holding d)
 (clear a)
 (ontable a)
 (ontable c)
 (on e b)
 (on f c)
 (on b f)
)
Checking if state has already been observed
State has been observed. Choosing another action
Chosen Action: 
Action pick-up
Instantiations:
?X0 - block : a 
Preconditions:
(and (handempty)
  (clear a)
  (ontable a))
Effects:
(and (holding a)
  (not (handempty)
  (not (clear a)
  (not (ontable a))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (clear d)
 (holding a)
 (ontable c)
 (on e b)
 (on f c)
 (on d e)
 (on b f)
)
Checking if state has already been observed
State has not been observed
Mirroing delta: 19.0
Starting recognising
Planning for problem 1 starting
Setting initial state to current state
Generating plan
Plan's cost: 19.0
Reseting initial state of problem
Planning for problem 2 starting
Setting initial state to current state
Generating plan
Plan's cost: 17.0
Reseting initial state of problem
Planning for problem 3 starting
Setting initial state to current state
Generating plan
Plan's cost: 11.0
Reseting initial state of problem
Generating scores for problems
Score for problem 1: 1.2340980408667956E-4
Score for problem 2: 9.118819655545162E-4
Score for problem 3: 9.118819655545162E-4
Calculating summed score
Total score: 0.001947173735195712
Final probability: 0.06337893833303762
Final probability: 0.4683105308334812
Final probability: 0.4683105308334812
Recognising Complete!
Highest probability: 0.4683105308334812
Second highest: 0.4683105308334812
Difference between probabilities is less than epsilon. Choosing action.
## Action Made:
Action pick-up
Instantiations:
?X0 - block : a 
Preconditions:
(and (handempty)
  (clear a)
  (ontable a))
Effects:
(and (holding a)
  (not (handempty)
  (not (clear a)
  (not (ontable a))

## New State:
(and (clear d)
 (holding a)
 (ontable c)
 (on e b)
 (on f c)
 (on d e)
 (on b f)
)



Checking if completed enough steps to act optimal
Still acting suspicious
Randomising actions
Chosen Action: 
Action stack
Instantiations:
?X0 - block : a 
?X1 - block : d 
Preconditions:
(and (clear d)
  (holding a))
Effects:
(and (handempty)
  (clear a)
  (on a d)
  (not (clear d)
  (not (holding a))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (handempty)
 (clear a)
 (ontable c)
 (on e b)
 (on f c)
 (on d e)
 (on b f)
 (on a d)
)
Checking if state has already been observed
State has not been observed
Mirroing delta: 20.0
Starting recognising
Planning for problem 1 starting
Setting initial state to current state
Generating plan
Plan's cost: 20.0
Reseting initial state of problem
Planning for problem 2 starting
Setting initial state to current state
Generating plan
Plan's cost: 18.0
Reseting initial state of problem
Planning for problem 3 starting
Setting initial state to current state
Generating plan
Plan's cost: 12.0
Reseting initial state of problem
Generating scores for problems
Score for problem 1: 4.5399929762484854E-5
Score for problem 2: 3.3546262790251185E-4
Score for problem 3: 3.3546262790251185E-4
Calculating summed score
Total score: 7.163251855675085E-4
Final probability: 0.06337893833303762
Final probability: 0.46831053083348123
Final probability: 0.46831053083348123
Recognising Complete!
Highest probability: 0.46831053083348123
Second highest: 0.46831053083348123
Difference between probabilities is less than epsilon. Choosing action.
## Action Made:
Action stack
Instantiations:
?X0 - block : a 
?X1 - block : d 
Preconditions:
(and (clear d)
  (holding a))
Effects:
(and (handempty)
  (clear a)
  (on a d)
  (not (clear d)
  (not (holding a))

## New State:
(and (handempty)
 (clear a)
 (ontable c)
 (on e b)
 (on f c)
 (on d e)
 (on b f)
 (on a d)
)



Checking if completed enough steps to act optimal
Still acting suspicious
Randomising actions
Chosen Action: 
Action unstack
Instantiations:
?X0 - block : a 
?X1 - block : d 
Preconditions:
(and (handempty)
  (clear a)
  (on a d))
Effects:
(and (clear d)
  (holding a)
  (not (handempty)
  (not (clear a)
  (not (on a d))

Action is applicable to state
Applying action to temporary state
Temporary state after action: (and (clear d)
 (holding a)
 (ontable c)
 (on e b)
 (on f c)
 (on d e)
 (on b f)
)
Checking if state has already been observed
State has been observed. Choosing another action
Execution terminated: No more valid actions
Final state:
(and (handempty)
 (clear a)
 (ontable c)
 (on e b)
 (on f c)
 (on d e)
 (on b f)
 (on a d)
)
